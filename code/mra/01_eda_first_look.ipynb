{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# this will make sure the root folder is the current working directory\n",
    "from os import chdir, getcwd\n",
    "from pyprojroot.here import here\n",
    "os.chdir(here())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv(\n",
    "     \"./data/01_input/Supermarket_customers.csv\",\n",
    "    delimiter=\"\\t\",              # note: \\t because its a tab separated and not comma separated file\n",
    "    parse_dates=[\"Dt_Customer\"], # parse as dates\n",
    "    dayfirst=True\n",
    ") \n",
    "\n",
    "# transform columns for sane column names\n",
    "df.columns = (df.columns\n",
    "                .str.replace('(?<=[a-z])(?=[A-Z])', '_', regex=True)\n",
    "                .str.lower()\n",
    "             )\n",
    "\n",
    "# remove absurd and yolo for now\n",
    "df = df[~df[\"marital_status\"].isin([\"Absurd\", \"YOLO\"])]\n",
    "\n",
    "# replace alone -> single\n",
    "df[\"marital_status\"] = df[\"marital_status\"].replace(\"Alone\", \"Single\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_dataframe(df):\n",
    "    # Container for all statistics\n",
    "    all_stats = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_data = df[col]\n",
    "        num_missing = col_data.isna().sum()\n",
    "        prop_missing = num_missing / len(col_data)\n",
    "\n",
    "        if pd.api.types.is_datetime64_any_dtype(col_data):\n",
    "            # Convert to numeric timestamps for calculations\n",
    "            col_numeric = col_data.dropna().astype(\"int64\")  # Dates as nanoseconds since epoch\n",
    "            all_stats.append({\n",
    "                \"variable\": col,\n",
    "                \"type\": \"datetime\",\n",
    "                \"mean\": pd.to_datetime(col_numeric.mean(), unit=\"ns\") if not col_numeric.empty else None,\n",
    "                \"min\": col_data.min(),\n",
    "                \"p05\": col_data.quantile(0.05),\n",
    "                \"p50\": col_data.median(),\n",
    "                \"p95\": col_data.quantile(0.95),\n",
    "                \"max\": col_data.max(),\n",
    "                \"num_missing\": num_missing,\n",
    "                \"prop_missing\": prop_missing\n",
    "            })\n",
    "        elif pd.api.types.is_numeric_dtype(col_data):\n",
    "            all_stats.append({\n",
    "                \"variable\": col,\n",
    "                \"type\": \"numeric\",\n",
    "                \"mean\": round(col_data.mean(), 4) if not col_data.empty else None,\n",
    "                \"min\": col_data.min(),\n",
    "                \"p05\": col_data.quantile(0.05),\n",
    "                \"p50\": col_data.median(),\n",
    "                \"p95\": col_data.quantile(0.95),\n",
    "                \"max\": col_data.max(),\n",
    "                \"num_missing\": num_missing,\n",
    "                \"prop_missing\": prop_missing\n",
    "            })\n",
    "        elif isinstance(col_data.dtype, pd.CategoricalDtype) or col_data.dtype == \"object\":\n",
    "            all_stats.append({\n",
    "                \"variable\": col,\n",
    "                \"type\": \"categorical\",\n",
    "                \"mean\": None,\n",
    "                \"min\": None,\n",
    "                \"p05\": None,\n",
    "                \"p50\": None,\n",
    "                \"p95\": None,\n",
    "                \"max\": None,\n",
    "                \"num_unique\": col_data.nunique(),\n",
    "                \"num_missing\": num_missing,\n",
    "                \"prop_missing\": prop_missing\n",
    "            })\n",
    "\n",
    "    # Convert list of dictionaries to a DataFrame\n",
    "    summary_df = pd.DataFrame(all_stats)\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "s1  = summarize_dataframe(df)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## regress income on regressors to estimate missing income\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define the list of predictor variables (with categorical columns included)\n",
    "regressors = [\"year_birth\", \"education\", \"marital_status\", \"kidhome\", \"teenhome\",\n",
    "              \"recency\", \"mnt_wines\", \"mnt_fruits\", \"mnt_meat_products\", \"mnt_fish_products\",\n",
    "              \"mnt_sweet_products\", \"mnt_gold_prods\"]\n",
    "\n",
    "# Separate rows with missing and non-missing income\n",
    "df_missing = df[df[\"income\"].isna()]\n",
    "df_non_missing = df.dropna(subset=[\"income\"])\n",
    "\n",
    "# One-hot encode the categorical variables\n",
    "df_non_missing_encoded = pd.get_dummies(df_non_missing[regressors], drop_first=True)\n",
    "df_missing_encoded = pd.get_dummies(df_missing[regressors], drop_first=True)\n",
    "df_all_obs_encoded = pd.get_dummies(df[regressors], drop_first=True)\n",
    "\n",
    "# Ensure the training and missing data have the same columns (in case of mismatched categories)\n",
    "df_non_missing_encoded, df_missing_encoded = df_non_missing_encoded.align(df_missing_encoded, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "# Train a linear regression model on non-missing data\n",
    "X_train = df_non_missing_encoded\n",
    "y_train = df_non_missing[\"income\"]\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict missing values\n",
    "predicted_income = model.predict(df_missing_encoded)\n",
    "\n",
    "# Impute the missing values in the original dataframe\n",
    "# df.loc[df[\"income\"].isna(), \"income\"] = predicted_income\n",
    "\n",
    "# predict full (for comparison with available info)\n",
    "predicted_income_full_df = model.predict(df_all_obs_encoded)\n",
    "df[\"income_pred\"] = predicted_income_full_df\n",
    "\n",
    "df.to_csv(\"data/02_inter/tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get correlations \n",
    "df_full_encoded = pd.get_dummies(df, drop_first=True)\n",
    "df_corr = df_full_encoded.corr()\n",
    "\n",
    "# heatmap\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(\n",
    "    round(df_corr,2), \n",
    "    cmap='RdBu',\n",
    "    annot=True,\n",
    "    annot_kws={\"size\": 5},\n",
    "    vmin=-1, vmax=1,\n",
    "    cbar=False\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def summary_stats_by_group(df, group_var, target_var):\n",
    "    \n",
    "    # Calculate the summary statistics\n",
    "    summary = df.groupby(group_var)[target_var].agg(\n",
    "        count=\"count\",  # Count the number of occurrences\n",
    "        mean=\"mean\",\n",
    "        min=\"min\",\n",
    "        max=\"max\",\n",
    "        p01=lambda x: x.quantile(0.01),\n",
    "        p05=lambda x: x.quantile(0.05),\n",
    "        p10=lambda x: x.quantile(0.10),\n",
    "        p25=lambda x: x.quantile(0.25),\n",
    "        p50=lambda x: x.quantile(0.50),\n",
    "        p75=lambda x: x.quantile(0.75),\n",
    "        p90=lambda x: x.quantile(0.90),\n",
    "        p95=lambda x: x.quantile(0.95),\n",
    "        p99=lambda x: x.quantile(0.99)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Sort by mean value (descending order)\n",
    "    summary_sorted = summary.sort_values(by=\"mean\", ascending=True)\n",
    "\n",
    "    return summary_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if \"mnt_total\" not in df.columns: df[\"mnt_total\"] = df.filter(like=\"mnt\").sum(axis=1)\n",
    "if \"num_total\" not in df.columns: df[\"num_total\"] = df.filter(like=\"num\").sum(axis=1)\n",
    "\n",
    "# if cond so that does not run more than once\n",
    "df.filter(regex=\"mnt|num\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# summary by education, target variable: income\n",
    "summary_stats_by_group(df, group_var=\"education\", target_var=\"income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# summary by education, target variable: mnt_total\n",
    "summary_stats_by_group(df, group_var=\"education\", target_var=\"mnt_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# summary by education, target variable: income\n",
    "summary_stats_by_group(df, group_var=\"education\", target_var=\"num_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# summary by education, target variable: income\n",
    "summary_stats_by_group(df, group_var=\"marital_status\", target_var=\"income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# summary by education, target variable: mnt_total\n",
    "summary_stats_by_group(df, group_var=\"marital_status\", target_var=\"mnt_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# summary by education, target variable: num_total\n",
    "summary_stats_by_group(df, group_var=\"marital_status\", target_var=\"num_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_violin_strip(df, group_var, target_var, figsize=(6,6), jitter=True, cut=0):\n",
    "    # Create a figure for the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Create the violin plot (horizontal)\n",
    "    ax = sns.violinplot(\n",
    "        x=target_var, y=group_var, data=df, color=\"lightblue\", cut=cut, split=True\n",
    "    )\n",
    "    ax.set(xlabel=None, ylabel=None)\n",
    "\n",
    "    # Title and labels\n",
    "    plt.title(f\"Distribution of {target_var} \\nby {group_var}\", loc=\"left\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_violin_strip(df, group_var=\"marital_status\", target_var=\"mnt_total\")\n",
    "plot_violin_strip(df, group_var=\"education\", target_var=\"mnt_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_selected_features(df, features, target_var=None, nrows=5, ncols=5, figsize=(20, 20)):\n",
    "    \"\"\"\n",
    "    Visualizes selected features of a DataFrame grouped by a target variable.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input dataset.\n",
    "    - features (list): A list of feature names to visualize.\n",
    "    - target_var (str): The column name of the target variable\n",
    "    - nrows (int): Number of rows in the subplot grid. Default is 5.\n",
    "    - ncols (int): Number of columns in the subplot grid. Default is 5.\n",
    "    - figsize (tuple): Size of the overall figure. Default is (20, 20).\n",
    "    \"\"\"\n",
    "    # Define the figure and axes for the grid of subplots\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "\n",
    "    \n",
    "    # Loop over each feature and plot based on its type\n",
    "    for i, feature in enumerate(features):\n",
    "        if i >= len(axes):  # Skip plotting if axes are exhausted\n",
    "            break\n",
    "        \n",
    "        if df[feature].dtype in [\"float64\", \"int64\"] and df[feature].max() > 5:  # Numerical features\n",
    "            sns.histplot(data=df, x=feature, hue=target_var, kde=True, ax=axes[i])\n",
    "\n",
    "        elif df[feature].dtype in [\"category\", \"object\"]:  # Nominal features\n",
    "            sns.countplot(data=df, x=feature, hue=target_var, ax=axes[i])\n",
    "\n",
    "        else:  # Ordinal or other types\n",
    "            sns.violinplot(data=df, x=target_var, y=feature, ax=axes[i])\n",
    "        \n",
    "        # Set the title for the plot\n",
    "        axes[i].set_title(feature)\n",
    "        # axes[i].set_yscale(\"log\")  \n",
    "        axes[i].set(xlabel=None, ylabel=None)\n",
    "    \n",
    "    # Hide any remaining unused axes in the grid\n",
    "    for j in range(len(features), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "num_features = [\n",
    "    \"mnt_wines\",\n",
    "    \"mnt_fruits\",\n",
    "    \"mnt_meat_products\",\n",
    "    \"mnt_fish_products\",\n",
    "    \"mnt_sweet_products\",\n",
    "    \"mnt_gold_prods\",\n",
    "    \"num_deals_purchases\", \n",
    "    \"num_web_purchases\", \n",
    "    \"num_catalog_purchases\", \n",
    "    \"num_store_purchases\", \n",
    "    \"num_web_visits_month\"\n",
    "]\n",
    "\n",
    "# Call the function for specific features\n",
    "visualize_selected_features(\n",
    "    df=df,\n",
    "    features=num_features,\n",
    "    nrows=4, \n",
    "    ncols=3, \n",
    "    figsize=(8,8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
